{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edacb949-7f43-44dd-b752-90d9bebb70df",
   "metadata": {},
   "source": [
    "# Generador datos sintéticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44580fd0-2d35-4fc0-9084-d562d01b4003",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En el desarrollo de modelos predictivos en acuicultura, la disponibilidad de un conjunto de datos amplio y representativo es un factor determinante para garantizar la precisión y robustez de los algoritmos. Sin embargo, en muchos casos, la recopilación de datos experimentales es limitada debido a restricciones logísticas, económicas o temporales. Para superar esta limitación, resulta fundamental implementar un algoritmo capaz de generar datos sintéticos de tamaño y peso de lenguados, asegurando así un dataset lo suficientemente extenso y variado. Este conjunto de datos sintético permitirá entrenar y validar de manera más efectiva los algoritmos de predicción de peso, mejorando su capacidad de generalización y minimizando el riesgo de sobreajuste a muestras reducidas.\n",
    "\n",
    "Si consideramos que $y = f(a, b, x)$ es la función que relaciona los parámetros $a$ y $b$ con la variable independiente $x$, la precisión en la estimación de $a$ y $b$ se ve afectada por la cantidad de datos disponibles. Bajo un enfoque bayesiano, la incertidumbre en la estimación se modela mediante una distribución de probabilidad:\n",
    "$$\n",
    "p(a, b | D) \\propto p(D | a, b) p(a, b)\n",
    "$$\n",
    "donde $D$ representa los datos observados. Cuando el tamaño de $D$ es reducido, la función de verosimilitud $p(D | a, b)$ tiene una varianza alta, lo que genera estimaciones más inciertas. Al aumentar el tamaño de $D$ con datos sintéticos plausibles, la estimación de p(a, b | D) se vuelve más precisa, reduciendo la varianza de los parámetros.\n",
    "\n",
    "Este artículo presenta las líneas de trabajo desarrolladas para la generación de un dataset sintético de tamaño y peso de lenguados, con el objetivo de proporcionar una base de datos suficientemente amplia y representativa para el entrenamiento, validación y mejora del modelos predictivo desarrollado. Se detallan las metodologías utilizadas en la generación de datos sintéticos, incluyendo la modelización estadística de distribuciones empíricas, técnicas de simulación basadas en procesos de crecimiento biológico y enfoques de aprendizaje automático para la síntesis de datos realistas. Además, se analizan los criterios de validación empleados para garantizar que los datos generados reflejen fielmente las tendencias y variabilidad observadas en poblaciones reales de lenguado (*Solea solea*), asegurando así su utilidad en el desarrollo de algoritmos precisos y generalizables para la predicción del peso a partir de variables alometricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb78bbeb-d48e-4db1-8d65-2ef1f80fe8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
